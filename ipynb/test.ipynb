{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlan/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append('..')\n",
    "import time\n",
    "import json\n",
    "from math import ceil, floor\n",
    "from os.path import join as opj, dirname\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from src.dataset import StatoilIcebergDataset\n",
    "from src.network import Net\n",
    "from src.settings import logger\n",
    "from src.tensorboard_logger import Logger\n",
    "from src.utils import mkdir_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_path = '/home/rlan/datasets/statoil-iceberg/test.json'\n",
    "\n",
    "BASE_DIR = '/home/rlan/projects/kaggle/kaggle-statoil-iceberg'\n",
    "CHECKPOINTS_PATH = opj(BASE_DIR, 'checkpoints')\n",
    "BATCH_SIZE = 256\n",
    "model_id = '1514653493'\n",
    "model_epoch = 164\n",
    "\n",
    "model_path = opj(CHECKPOINTS_PATH, model_id, 'model_%d' % model_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = T.Compose([T.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = StatoilIcebergDataset(test_data_path, transform=transform)\n",
    "loader = DataLoader(dataset, shuffle=False, batch_size=BATCH_SIZE, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d (2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (conv2): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (conv3): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (conv4): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (conv5): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (conv6): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv6_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (fc1): Linear(in_features=20736, out_features=120)\n",
       "  (fc1_bn): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (fc2): Linear(in_features=120, out_features=80)\n",
       "  (fc2_bn): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (fc3): Linear(in_features=80, out_features=2)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(model_path)\n",
    "net = Net(input_channel=2).cuda() if torch.cuda.is_available() else Net(input_channel=2)\n",
    "net.load_state_dict(checkpoint)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "answers = torch.Tensor().cuda()\n",
    "for i_batch, sampled_batch in enumerate(loader):\n",
    "    data, target = sampled_batch\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        data, target = Variable(data).cuda(), Variable(target).cuda()\n",
    "    else:\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "    pred = net(data)\n",
    "    pred_softmax = torch.nn.functional.softmax(pred)\n",
    "    answers = torch.cat((answers, pred_softmax[:, 1].data), dim=0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    answers = answers.cpu()\n",
    "answers = answers.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct submission with both predictions and IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_data_path, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_ids = [d['id'] for d in test_data]\n",
    "submission = pd.DataFrame({'id': test_ids, 'is_iceberg': answers})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Write submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(opj(BASE_DIR, 'submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
